Important things to put in the report.
1. Justify selection of algortihms
2. Correctness proofs on code
3. Complexity analysis of overall algorithm
4. Justify efficiency tradeoffs in light of performance
5. Document all iterations and why that path was chosen
6. Appendices must include
  i. Testing/Correctness/Verification (1 section)
  ii. Runtime Complexity and Walltime (1 section)
  iii. Performance (according to the aforementioned criterion)
  iv. ustification for the algorithm selected in your final implementation out of the set of implementations you tested
7. explore the problem and solution space, and report any ideas, interesting insights, and rationale you uncover for tackling the problem
8. Any useful figures, plots, tables, or analyses are allowed to illustrate your level of depth at which you thought about the problem and your solutions.
9. Make sure all code is well-commented

FGSM algorithm
Justification - The Fast Gradient Sign Method (FGSM) is a method for generating adversial attacks that is simple yet effective.  "FGSM is a single step
attack, ie.. the perturbation is added in a single step instead of adding it over a loop (Iterative attack). (INSERT CITATION 1)". The method works by 
calculating the gradient of the loss with respect to the original image.  The algorithm then adds a perturbation to to the image based on the gradient's
sign.  The algorithm modifies the image into its adversial version bt making small perturbations.  This allows the adversial image to look very similar
to the original image while still fooling the computer.  The way this is accomplished is by finding how much each pixel contributes to the loss.  This
is a quick process because the algorithm will follow the chain rule in finding pixels that contribute to maximum loss.  The chain rule breaks the
computation into smaller parts, making the calculation of the gradient more accurate and efficient.  The first step in this method is to feed the model
input data and then calculate the loss.  The gradient with respect to the loss is then calculated.  From this gradient a perturbation is added in order
to generate the new adversial model.  We chose this method for many reasons.  The first reason is the computational efficiency of the FGSM method.  It
can generate adversial attacks on a model quickly.  This method is also easy to implement because it requires a calculation of the gradient of the loss
and then addition or subtraction of perturbations based on the sign of the gradient.  Another reason we chose to implement this method is due to its 
adaptability.  The FGSM method can be used for any machine learning model and therefore we knew it would be able to work on the binary image classifier.
The method has been proven very effective on a wide range of models.  Overall, the reason this model was selected was due to its basic implementation,
computational efficiency, and effectiveness.

Spatial-Transformation Based Attack
Justification - The Spatial-Transformation Based Attack (STBA) is an adversial attack that applies a spatial transformation to the input data in order to
create an adversial image.  "All the existing approaches directly modify pixels, but we aim to smoothly change the geometry of the scene while keeping the
original appearance
